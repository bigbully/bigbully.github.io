---
layout: post
title: Nimbus
description: 
category: storm
---

Nimbus的核心代码在backtype.storm.daemon.nimbus.clj中

数据结构
-----------

nimbus共享数据结构使用nimbus-data函数获得，其中包括一些Nimbus使用的公共类：

	(defn nimbus-data [conf inimbus]
	  (let [forced-scheduler (.getForcedScheduler inimbus)]
    {:conf conf
     :inimbus inimbus
     :submitted-count (atom 0)
     :storm-cluster-state (cluster/mk-storm-cluster-state conf)
     :submit-lock (Object.)
     :heartbeats-cache (atom {})
     :downloaders (file-cache-map conf)
     :uploaders (file-cache-map conf)
     :uptime (uptime-computer)
     :validator (new-instance (conf NIMBUS-TOPOLOGY-VALIDATOR))
     :timer (mk-timer :kill-fn (fn [t]
                                 (log-error t "Error when processing event")
                                 (halt-process! 20 "Error when processing an event")
                                 ))
     :scheduler (mk-scheduler conf inimbus)
     }))

 1. conf用来表示配置信息
 2. inimbus是Thrift的接口实现
 3. submitted-count表示Topology的提交数目
 4. storm-cluster-state用于将数据存储到ZK中以及从ZK中读取数据
 5. submit-lock 提交时用的锁
 6. heartbeats-cache 心跳用的cache
 7. downloaders和uploaders分别对应的是用户提交或下载Topology jar包时用到的缓存
 8. uptime记录启动耗时
 9. validator用来验证Topology，不过默认的Topology为空，用来扩展的
 10. 创建一个timer，timer的实现在timer.clj中
 11. 根据inimbus中ForcedScheduler创建一个调度器scheduler

分布式启动
--------------

main方法如下：

	(defn -main []
	  (-launch (standalone-nimbus)))

-launch方法如下，接收nimbus参数，和storm相关配置一起作为launch-server!的函数参数调用：

	(defn -launch [nimbus]
	  (launch-server! (read-storm-config) nimbus)启动)

在config.clj中实现了read-storm-config函数，他调用java的Utils.readStormConfig静态方法从配置文件中读出配置，使用clojurify-structure转化成clojure的数据结构(如list, map)，通过validate-configs-with-schemas进行验证后返回conf。

	(defn read-storm-config
	  []
	  (let [conf (clojurify-structure (Utils/readStormConfig))]
    (validate-configs-with-schemas conf)
    conf))

standalone-nimbus方法：

	(defn standalone-nimbus []
	  (reify INimbus
	    (prepare [this conf local-dir]
	      )
	    (allSlotsAvailableForScheduling [this supervisors topologies topologies-missing-assignments]
	      (->> supervisors
	           (mapcat (fn [^SupervisorDetails s]
	                     (for [p (.getMeta s)]
	                       (WorkerSlot. (.getId s) p))))
	           set ))
	    (assignSlots [this topology slots]
	      )启动
	    (getForcedScheduler [this]
	      nil )
	    (getHostName [this supervisors node-id]
	      (if-let [^SupervisorDetails supervisor (get supervisors node-id)]
	        (.getHost supervisor)))
	    ))

这里定义了一个协议实现standalone-nimbus， 它实现了java接口INimbus，并实现了其中的三个方法：

 1. allSlotsAvailableForScheduling方法会把传入参数的SupervisorDetails集合supervisors，根据其中定义的id和不同的port构造WorkerSlot，合并后转化成set。
 2. getForcedScheduler返回空SupervisorDetails
 3. getHostName使用if-let函数，在supervisors这个map中查找node-id，如果找到，则赋值到supervisor上，并返回host。如果没有找到，则什么也不做。启动

当我们获得了INimbus的实现后终于可以进行启动前的最后准备了，来看launch-server!函数：

	(defn launch-server! [conf nimbus]
	  (validate-distributed-mode! conf)
	  (let [service-handler (service-handler conf nimbus)
        options (-> (TNonblockingServerSocket. (int (conf NIMBUS-THRIFT-PORT)))
                    (THsHaServer$Args.)
                    (.workerThreads 64)
                    (.protocolFactory (TBinaryProtocol$Factory. false true (conf NIMBUS-THRIFT-MAX-BUFFER-SIZE)))
                    (.processor (Nimbus$Processor. service-handler))
                    )
       server (THsHaServer. (do (set! (. options maxReadBufferBytes)(conf NIMBUS-THRIFT-MAX-BUFFER-SIZE)) options))]
    (.addShutdownHook (Runtime/getRuntime) (Thread. (fn [] (.shutdown service-handler) (.stop server))))
    (log-message "Starting Nimbus server...")
    (.serve server)))

这个方法依次做了以下几步：

 1. 对conf进行分布式校验，如果conf中配置的是本地模式，则直接异常抛出
 2. 通过service-handle函数创建handler
 3. 通过一个串行的宏创建Thrift的processor，并用handler作为处理器
 4. 之后使用conf中的属性重置options中的maxReadBufferBytes，并使用options创建THsHaServer
 5. 加入一个关闭handler和server的关闭钩子
 6. 打印一行日志
 7. 启动server

下面来看看如何初始化handler，首先使用了一个common.clj中定义的宏：

	(defmacro defserverfn [name & body]
	  `(let [exec-fn# (fn ~@body)]
    (defn ~name [& args#]
      (try-cause
        (apply exec-fn# args#)
      (catch InterruptedException e#
        (throw e#))
      (catch Throwable t#
        (log-error t# "Error on initialization of server " ~(str name))
        (halt-process! 13 "Error on initialization")
        )))))

这个宏会把函数体放在try-catch中执行，并抛出InterruptedException，并所有Throwable异常进行日志打印。

然后用这个宏来创建handler：

	(defserverfn service-handler [conf inimbus]
	  (.prepare inimbus conf (master-inimbus-dir conf))
	  (log-message "Starting Nimbus with conf " conf)
	  (let [nimbus (nimbus-data conf inimbus)]
	    (.prepare ^backtype.storm.nimbus.ITopologyValidator (:validator nimbus) conf)
	    (cleanup-corrupt-topologies! nimbus)
	    (doseq [storm-id (.active-storms (:storm-cluster-state nimbus))]
	      (transition! nimbus storm-id :startup))
	    (schedule-recurring (:timer nimbus)
                        0
                        (conf NIMBUS-MONITOR-FREQ-SECS)
                        (fn []
                          (when (conf NIMBUS-REASSIGN)
                            (locking (:submit-lock nimbus)
                              (mk-assignments nimbus)))
                          (do-cleanup nimbus)
                          ))
	    ;; Schedule Nimbus inbox cleaner
	    (schedule-recurring (:timer nimbus)(defn nimbus-data [conf inimbus]
	  (let [forced-scheduler (.getForcedScheduler inimbus)]
    {:conf conf
     :inimbus inimbus
     :submitted-count (atom 0)
     :storm-cluster-state (cluster/mk-storm-cluster-state conf)
     :submit-lock (Object.)
     :heartbeats-cache (atom {})
     :downloaders (file-cache-map conf)
     :uploaders (file-cache-map conf)
     :uptime (uptime-computer)
     :validator (new-instance (conf NIMBUS-TOPOLOGY-VALIDATOR))
     :timer (mk-timer :kill-fn (fn [t]
                                 (log-error t "Error when processing event")
                                 (halt-process! 20 "Error when processing an event")
                                 ))
     :scheduler (mk-scheduler conf inimbus)
     }))(defn nimbus-data [conf inimbus]
	  (let [forced-scheduler (.getForcedScheduler inimbus)]
    {:conf conf
     :inimbus inimbus
     :submitted-count (atom 0)
     :storm-cluster-state (cluster/mk-storm-cluster-state conf)
     :submit-lock (Object.)
     :heartbeats-cache (atom {})
     :downloaders (file-cache-map conf)
     :uploaders (file-cache-map conf)
     :uptime (uptime-computer)
     :validator (new-instance (conf NIMBUS-TOPOLOGY-VALIDATOR))
     :timer (mk-timer :kill-fn (fn [t]
                                 (log-error t "Error when processing event")
                                 (halt-process! 20 "Error when processing an event")
                                 ))
     :scheduler (mk-scheduler conf inimbus)
     }))
                        0
                        (conf NIMBUS-CLEANUP-INBOX-FREQ-SECS)
                        (fn []
                          (clean-inbox (inbox nimbus) (conf NIMBUS-INBOX-JAR-EXPIRATION-SECS))
                          ))    
    (reify Nimbus$Iface
		...
	)))

介绍一下做了那些事情：

 1. 首先调用了inimbus的prepare方法，不过由于这个方法现在还是空方法，所以不产生任何作用
 2. 打印一行日志，随后进入let赋值的方法
 3. 通过nimbus-data方法把inimbus和conf封装成Nimbus共享数据结构，并赋予nimbus引用
 4. 之后执行ITopologyValidator的prepare方法，如果是DefaultTopologyValidator，则不执行任何操作
 5. cleanup-corrupt-topologies!方法会清楚哪些在ZK上还有但是本地目录没有的Topology，并调用 storm-cluster-state的remove-storm!方法把这些Topology移除
 6. 之后对所有活跃状态的Topology调用transition!方法，把状态设置为:start-up
 7. 使用nimbus中的timer定时执行mk-assignments， do-cleanup， clean-inbox方法。这三个方法在下文会详细分析
 8. 最后实现了Nimbus$Iface接口

下面按顺序分析一下每一个方法的实现，首先是submitTopologyWithOpts方法，这个方法老长了。直接在源码中用注释标明每行代码的意图：

	(^void submitTopologyWithOpts
        [this ^String storm-name ^String uploadedJarLocation ^String serializedConf ^StormTopology topology ^SubmitOptions submitOptions]
        (try 
          (assert (not-nil? submitOptions)) ;;对submitOptions做断言
          (validate-topology-name! storm-name) ;;验证Topology name中不能包含特殊字符
          (check-storm-active! nimbus storm-name false) ;;确保当前环境中没有同名的Topology正在运行
          (let [topo-conf (from-json serializedConf)] ;;把json的conf转成clojure的集合类型
            (try
              (validate-configs-with-schemas topo-conf) ;;对配置信息进行验证
              (catch IllegalArgumentException ex
                (throw (InvalidTopologyException. (.getMessage ex))))) ;;如果有误则抛出异常
            (.validate ^backtype.storm.nimbus.ITopologyValidator (:validator nimbus)
                       storm-name
                       topo-conf
                       topology)) ;;用ITopologyValidator对Topology进行验证，默认不执行任何操作
          (swap! (:submitted-count nimbus) inc) ;;原子的把submitted-count设置为1
          (let [storm-id (str storm-name "-" @(:submitted-count nimbus) "-" (current-time-secs)) ;;用Topology的name,index和当前时间设置Topology的id
                storm-conf (normalize-conf
                            conf
                            (-> serializedConf
                                from-json
                                (assoc STORM-ID storm-id)
                              (assoc TOPOLOGY-NAME storm-name))
                            topology) ;;用户传递过来的serializedConf加入Topology的id,name以及TOPOLOGY-KRYO-DECORATORS，TOPOLOGY-KRYO-REGISTER，TOPOLOGY-ACKER-EXECUTORS，TOPOLOGY-MAX-TASK-PARALLELISM四个属性
                total-storm-conf (merge conf storm-conf) ;;把conf与storm-conf进行合并，主要是用conf中默认的配置添加到total-storm-conf中
                topology (normalize-topology total-storm-conf topology);;之后会详细介绍这个方法
                storm-cluster-state (:storm-cluster-state nimbus)]
            (system-topology! total-storm-conf topology) ;;使用system-topology!方法对topology进行验证，之后会详细分析
            (log-message "Received topology submission for " storm-name " with conf " storm-conf)
            ;; lock protects against multiple topologies being submitted at once and
            ;; cleanup thread killing topology in b/w assignment and starting the topology
            (locking (:submit-lock nimbus);;以下逻辑加锁
              (setup-storm-code conf storm-id uploadedJarLocation storm-conf topology);;为当前topology创建本地目录，赋值jar文件，并写入序列化之后的storm配置信息和Topology信息。其中setup-jar方法根据conf中定义的启动模式是:distributed还是:local分别有不同的处理逻辑。:distributed会进行jar的拷贝，而:local则什么也不做。
              (.setup-heartbeats! storm-cluster-state storm-id);;为该topology在zk上创建心跳路径
              (let [thrift-status->kw-status {TopologyInitialStatus/INACTIVE :inactive TopologyInitialStatus/ACTIVE :active}];;把Java中的常量与clojure中的keyword做成映射
                (start-storm nimbus storm-name storm-id (thrift-status->kw-status (.get_initial_status submitOptions))));;启动storm
              (mk-assignments nimbus)));;为提交的Topology分配资源
          (catch Throwable e
            (log-warn-error e "Topology submission exception. (topology name='" storm-name "')")
            (throw e))))

在submitTopologyWithOpts函数中，使用了以下几个重要的函数：

 1. mk-assignments主要负责对当前及权重所有的Topology进行新一轮的任务调度。
		
		(defnk mk-assignments [nimbus :scratch-topology-id nil]
		  (let [conf (:conf nimbus) ;;配置信息
	        storm-cluster-state (:storm-cluster-state nimbus) ;;与zk交互用服务
	        ^INimbus inimbus (:inimbus nimbus) ;;inimbus接口
	        ;; read all the topologies
	        topology-ids (.active-storms storm-cluster-state) ;;从zk中读出所有活跃的topology的id
	        topologies (into {} (for [tid topology-ids] 
                              {tid (read-topology-details nimbus tid)})) ;;获取topology id和detail的映射，并放入map中
	        topologies (Topologies. topologies) ;封装成一个Topologies java对象
	        ;; read all the assignments
	        assigned-topology-ids (.assignments storm-cluster-state nil) ;;获取所有已经分配资源的Topology id的集合
	        existing-assignments (into {} (for [tid assigned-topology-ids]
                                        ;; for the topology which wants rebalance (specified by the scratch-topology-id)
                                        ;; we exclude its assignment, meaning that all the slots occupied by its assignment
                                        ;; will be treated as free slot in the scheduler code.
                                        (when (or (nil? scratch-topology-id) (not= tid scratch-topology-id))
                                          {tid (.assignment-info storm-cluster-state tid nil)})));;获取所有已经分配资源的topology的分配信息，如果需要rebalance的topology通过参数scratch-topology-id传入了，则把这个topology从已分配中剔除
	        ;; make the new assignments for topologies
	        topology->executor->node+port (compute-new-topology->executor->node+port
                                       nimbus
                                       existing-assignments
                                       topologies
                                       scratch-topology-id);;这个方法之后会分析，他为所有topology计算新的调度，并返回。       
	        now-secs (current-time-secs) ;;获取当前时间        
	        basic-supervisor-details-map (basic-supervisor-details-map storm-cluster-state);;从zk中获取和supervisor信息，并转化成id和supervisorDetail        
	        ;; construct the final Assignments by adding start-times etc into it
	        new-assignments (into {} (for [[topology-id executor->node+port] topology->executor->node+port
                                        :let [existing-assignment (get existing-assignments topology-id);;获取分配了资源的topology
                                              all-nodes (->> executor->node+port vals (map first) set);;获得所有的node集合
                                              node->host (->> all-nodes
                                                              (mapcat (fn [node]
										                          (if-let [host (.getHostName inimbus basic-supervisor-details-map node)]
                                                                          [[node host]]
                                                                          )))
                                                              (into {}));;获得node和host的对应关系
                                              all-node->host (merge (:node->host existing-assignment) node->host) ;; 合并得到所有的node对host的映射，如果有相同的node，则使用node->host中的值
                                              reassign-executors (changed-executors (:executor->node+port existing-assignment) executor->node+port) ;;通过对比获得所有重新分配过的Executor
                                              start-times (merge (:executor->start-time-secs existing-assignment)
                                                                (into {}
                                                                      (for [id reassign-executors]
                                                                        [id now-secs]
                                                                        )))]];;把重新分配的executor重新设定startTime
                                   {topology-id (Assignment.
                                                 (master-stormdist-root conf topology-id)
                                                 (select-keys all-node->host all-nodes)
                                                 executor->node+port
                                                 start-times)}))];;创建每个topology id与Assignment对应关系

	    ;; tasks figure out what tasks to talk to by looking at topology at runtime
	    ;; only log/set when there's been a change to the assignment
	    (doseq [[topology-id assignment] new-assignments ;;循环新分配好的topology的assignment
	            :let [existing-assignment (get existing-assignments topology-id)
	                  topology-details (.getById topologies topology-id)]]
	      (if (= existing-assignment assignment) ;;查看新旧assignment是否发生任何变化
	        (log-debug "Assignment for " topology-id " hasn't changed");;如果没有，打印一条日志
	        (do
	          (log-message "Setting new assignment for topology id " topology-id ": " (pr-str assignment))
	          (.set-assignment! storm-cluster-state topology-id assignment);;如果有，除了打印日志，还要同步到zk上
	          )))
		    (->> new-assignments
	          (map (fn [[topology-id assignment]]
	            (let [existing-assignment (get existing-assignments topology-id)]
	              [topology-id (map to-worker-slot (newly-added-slots existing-assignment assignment))] 
	              )))
	          (into {});;获得新增加的Executor转成workerSlot，并转化成topology-id与workerSlot的对应关系
	          (.assignSlots inimbus topologies));;之后通过inimbus把topologies和topology-id与workerSlot的对应关系同步到zk上
	    ))

 2.compute-new-topology->executor->node+port函数用来根据上一次资源分配的情况计算这次资源的分配：
 
		(defn compute-new-topology->executor->node+port [nimbus existing-assignments topologies scratch-topology-id]
		  (let [conf (:conf nimbus)
	        storm-cluster-state (:storm-cluster-state nimbus)
	        topology->executors (compute-topology->executors nimbus (keys existing-assignments));;获得 topology-id -> executors集合
	        ;; update the executors heartbeats first.
	        _ (update-all-heartbeats! nimbus existing-assignments topology->executors);;更新所有executors心跳
	        topology->alive-executors (compute-topology->alive-executors nimbus
                                                                     existing-assignments
                                                                     topologies
                                                                     topology->executors
                                                                     scratch-topology-id) ;;获取topology对alive-executors的集合
	        supervisor->dead-ports (compute-supervisor->dead-ports nimbus
                                                               existing-assignments
                                                               topology->executors
                                                               topology->alive-executors);;获取supervisor对dead-ports的集合
	        topology->scheduler-assignment (compute-topology->scheduler-assignment nimbus
                                                                               existing-assignments
                                                                               topology->alive-executors);;获取topology对应schedulerAssignmentImpl的集合
                                                                               
	        missing-assignment-topologies (->> topologies
                                           .getTopologies
                                           (map (memfn getId))
                                           (filter (fn [t]
                                                      (let [alle (get topology->executors t)
                                                            alivee (get topology->alive-executors t)]
                                                            (or (empty? alle);;1没有任何executor
                                                                (not= alle alivee);;2executor中有不存活的
                                                                (< (-> topology->scheduler-assignment
                                                                       (get t)
                                                                       num-used-workers )
                                                                   (-> topologies (.getById t) .getNumWorkers)
                                                                   ));;3实际使用的worker数量小于设置的worker数量
                                                            ))));;根据三个判断条件筛选出分配缺失的topology
	        all-scheduling-slots (->> (all-scheduling-slots nimbus topologies missing-assignment-topologies)
                                  (map (fn [[node-id port]] {node-id #{port}}))
                                  (apply merge-with set/union));;获得所有分配缺失的topology对应的workSlot信息，即node-id与port相关信息
        
	        supervisors (read-all-supervisor-details nimbus all-scheduling-slots supervisor->dead-ports);;获得topology对supervisorDetails的信息
	        cluster (Cluster. (:inimbus nimbus) supervisors topology->scheduler-assignment);;创建cluster对象

	        ;; call scheduler.schedule to schedule all the topologies
	        ;; the new assignments for all the topologies are in the cluster object.
	        _ (.schedule (:scheduler nimbus) topologies cluster);;调用void schedule(Topologies topologies, Cluster cluster)方法，这个方法会为需要的topology进行任务调度
	        new-scheduler-assignments (.getAssignments cluster);;获得任务调度的结果：topology-id对应SchedulerAssignment
	        ;; add more information to convert SchedulerAssignment to Assignment
	        new-topology->executor->node+port (compute-topology->executor->node+port new-scheduler-assignments)];;把topology-id与SchedulerAssignment对应关系转成topology-id对应{executor [node port]}}
		    ;; print some useful information.
		    (doseq [[topology-id executor->node+port] new-topology->executor->node+port ;;遍历
	            :let [old-executor->node+port (-> topology-id
                                          existing-assignments
                                          :executor->node+port);;获得已经存在的executor对应node+port
                  reassignment (filter (fn [[executor node+port]]
                                         (and (contains? old-executor->node+port executor)
                                              (not (= node+port (old-executor->node+port executor)))))
                                       executor->node+port)]];;和当前的进行对比，计算出重新分配的assignment
		      (when-not (empty? reassignment) ;;如果存在重新分配的情况
		        (let [new-slots-cnt (count (set (vals executor->node+port)))
	              reassign-executors (keys reassignment)]
	          (log-message "Reassigning " topology-id " to " new-slots-cnt " slots")
	          (log-message "Reassign executors: " (vec reassign-executors)))));;日志打印创建爱你了多少个workSlot和重新分配的executors
	    new-topology->executor->node+port));;最终返回新的topology对应的{executor [node port]}}
	 
 
 3. clean-inbox会被定时执行，清理过期jar包
  
		(defn clean-inbox [dir-location seconds]
		  "Deletes jar files in dir older than seconds."
		  (let [now (current-time-secs);;获取当前时间
		        pred #(and (.isFile %) (file-older-than? now seconds %));;定义匿名函数获取过期文件
		        files (filter pred (file-seq (File. dir-location)))];;过滤获得过期文件
		    (doseq [f files]
		      (if (.delete f);;删除文件
		        (log-message "Cleaning inbox ... deleted: " (.getName f))
		        ;; This should never happen
		        (log-error "Cleaning inbox ... error deleting: " (.getName f))
	        ))))

 4. do-cleanup定期清理
 
		(defn do-cleanup [nimbus]
		  (let [storm-cluster-state (:storm-cluster-state nimbus)
	        conf (:conf nimbus)
	        submit-lock (:submit-lock nimbus)] 
	    (let [to-cleanup-ids (locking submit-lock ;;首先加锁
	                           (cleanup-storm-ids conf storm-cluster-state))] ;;获得需要清理的topologyId
	      (when-not (empty? to-cleanup-ids) ;;如果不为空
	        (doseq [id to-cleanup-ids]
	          (log-message "Cleaning up " id)
	          (.teardown-heartbeats! storm-cluster-state id) ;;清除心跳
	          (.teardown-topology-errors! storm-cluster-state id);;清除topology错误信息
	          (rmr (master-stormdist-root conf id));;删除topology对应本地目录
	          (swap! (:heartbeats-cache nimbus) dissoc id));;从心跳缓存中删除topologyId
	        ))))

 5. normalize-topology
 6. system-topology!
 7. start-storm




本地启动
-----------------

当我们在本机测试Topology时会用到：

	LocalCluster cluster = new LocalCluster();
    cluster.submitTopology("test", conf, builder.createTopology());

所以我非常想了解一下submitTopology方法都做了些什么。深入源码后我发现LocalCluster类是用clojure实现的。

LocalCluster类在ns中定义了如下所示的gen-class，他实现了java中的ILocalCluster

	LocalCluster.clj...
	
	(ns backtype.storm.LocalCluster
	  (:use [backtype.storm testing config])
	  (:import [java.util Map])
	  (:gen-class
	    :init init
	    :implements [backtype.storm.ILocalCluster]
	    :constructors {[] [] [java.util.Map] []}
	    :state state))


init方法中提供了两个构造函数：

	LocalCluster.clj...
	
	(defn -init
	  ([]
	   (let [ret (mk-local-storm-cluster
               :daemon-conf
               {TOPOLOGY-ENABLE-MESSAGE-TIMEOUTS true})]
     [[] ret]))
	  ([^Map stateMap]
	   [[] stateMap]))

其中无参的构造函数会调用mk-local-storm-cluster方法返回带着配置信息的map，除此之外还提供java.util.Map类型的构造函数，map会直接设置到state属性中。

做完上述铺垫后，终于可以看看submitTopology的实现了。

	LocalCluster.clj...

	(defn -submitTopology
	  [this name conf topology]
	  (submit-local-topology
	    (:nimbus (. this state)) name conf topology))

submitTopology方法接收三个参数，name、conf自不必多说，topology是我们通过TopologyBuilder构建的StormTopology。接下来会调用submit-local-topology方法，并把this.state中的nimbus对应的配置和name, conf, topology作为实参。

以为submit-local-topology和其他local方法实际上都是本地测试用的，所以被放在testing.clj中，代码如下：

	testing.clj...

	(defn submit-local-topology
	  [nimbus storm-name conf topology]
	  (when-not (Utils/isValidConf conf)
	    (throw (IllegalArgumentException. "Topology conf is not json-serializable")))
	  (.submitTopology nimbus storm-name nil (to-json conf) topology))

这个方法校验了conf，如果校验失败，抛出IllegalArgumentException异常，如果正常，则把conf转成json之后调用java类Nimbus中的Thrift服务submitTopology提交Topology。











